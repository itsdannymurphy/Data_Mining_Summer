{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Clustering and Ensemble Learning\n",
    "### Danny Murphy, Kerry Nakayama, Brandon Tarr\n",
    "\n",
    "## Introduction\n",
    "In lab 1 we tackled the rather large dataset provided by Expedia through Kaggle and determined that for the scope of our assignments and learning objectives this semester we would reduce our focus to records that fully transacted as \"bookings\" (~10% of original dataset size) and the top five classes that we've been tasked with classifying (~10% of bookings dataset size). We then used the roughly 410,000 records to explore logistic regression and support vector machines consistently acheiving around 36% accuracy in the Mini Lab. In Lab 2 we further explored the AdaBoostClassifier, ExtraTreesClassifier,  RandomForestClassifier, and GradientBoostingClassifier algorithms concluding that Random Forest increasing classification accuracy in the most computationally efficient manner. Gradient Boosted Trees by far performed the best but at a considerably higher computational expense. We also did a significant amount of investigation of feature importances that included experimentation with a variety of different data subsets finding that a small group of 2-3 features tend to produce smaller, more efficient, and more accurate classification models than the full dataset. \n",
    "Following in the same vein, we're interested in clustering as an alternative preprocessing strategy for data reduction or feature importance determination prior to making classification attempts. This lab will attempt a variety of clustering methods who's outputs will then be used in an ensemble learning model based on the most successful classification algorithms from Lab 2, namely the decision tree based classifiers that performed best.\n",
    "\n",
    "### Sources:\n",
    "We make extensive use of the code provided in the three clustering Notebooks for the class and code from Sebastian Raschka book \"Python Machine Learning\".\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "We've outlined the business case for understanding these data in previous labs, but as a reminder, Expedia has provided logs of customer behavior captured during their online search sessions. The purpose of these data are to take customer behavior and use it to predict which hotel clusters the customers are likely to book. Hotel clusters are based on Expedia's algorithm which groups hotels based on price, customer ratings, and location. A hotel cluster example might be hotels located in a downtown location in the $250-300 per night price range with an average rating between 3-4 stars (out of 5). However since the data is from Kaggle all the clusters are masked by an id. We are unable to see the star rating or specific location of each hotel cluser. Expedia has provided a training data set which is a random sample of customer behavior and hotel cluster bookings from 2013-2014. The objective is to use data mining techniques to develop a predictive algorithm based on these data and then apply it to a test data set consisting of randomly sampled customer behavior from 2015. Since this is part of a Kaggle competition, only Expedia knows the true outcome of how 2015 customers booked by hotel cluster. The success of the predictive algorithm will be based on the rate of accurate classification of 2015 Expedia customers into the appropriate hotel cluster. A successful submission will include 5 hotel cluster recommendations for each line item of the test data set. Scoring is based on whether the correct cluster is presented in the 5 clusters as well as where it is ranked in the 5 recommendation. The test data set has two less variables than the training data set which includes is booked since all the test data is actual bookings and the hotel cluster chosen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "We've already discussed the prohibitive size of the original dataset and reduced its size accordingly. After reduction, the variable that measures distance between a user's target hotel and location from which they are conducting the search (orig_destination_distance) was missing in approximately 25% of the records. We were able to successfully impute 99.6% of the missing values using three features ('posa_continent', 'hotel_continent', 'hotel_country').\n",
    "\n",
    "## Modeling and Evaluation\n",
    "\n",
    "### Train and Adjust Parameters\n",
    "\n",
    "### Evaluate and Compare\n",
    "\n",
    "### Visualize Results\n",
    "\n",
    "### Summarize the Ramifications\n",
    "\n",
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
